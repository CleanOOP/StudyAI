{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwANG721zzXlpBGnyBYcCs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CleanOOP/StudyAI/blob/Week4Homework/4weekBasicHomeWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#이번 과제는 자연어 task 중 하나인 MNLI를 해결하는 모델을 HuggingFace로 학습하는 것입니다. MNLI를 요약하면 다음과 같습니다.\n",
        "\n",
        "#- 입력: premise에 해당하는 문장과 hypothesis에 해당하는 문장 두 개가 입력으로 들어옵니다.\n",
        "#- 출력: 분류 문제로, 두 문장이 들어왔을 때 다음 세 가지를 예측하시면 됩니다.\n",
        "#    - Entailment: 두 문장에 논리적 모순이 없습니다.\n",
        "#    - Neutral: 두 문장은 논리적으로 관련이 없습니다.\n",
        "#    - Contradiction: 두 문장 사이에 논리적 모순이 존재합니다.\n",
        "\n",
        "#이때, 다음 요구사항이 담긴 colab notebook을 만들어내시면 됩니다:\n",
        "\n",
        "#-   `load_dataset(\"nyu-mll/glue\", \"mnli\")` 로 dataset을 불러옵니다.\n",
        "#    - 학습 때는 `train` split만 활용하셔야 합니다. 나머지 split은 사용불가입니다.\n",
        "#    - Validation data가 필요한 경우, `train` split에서 가져오셔야 합니다.\n",
        "#-   `trainer.train()`를 통해 학습된 log가 남아있어야 합니다.\n",
        "#-   Dataset의 `validation_matched`에 대한 성능을 출력하고, 50%를 넘기셔야 합니다.\n",
        "\n",
        "#이전 과제와 똑같이 validation data 유무, 모델 architecture, hyper-parameter 등은 위의 조건만 만족한다는 가정 하에서 마음대로 수정하셔도 됩니다.\n",
        "## 제출자료\n",
        "\n",
        "#위의 요구사항이 만족된 notebook을 public github repository에 업로드하여 링크를 제출합니다.\n",
        "#반드시 출력 결과가 남아있어야 합니다"
      ],
      "metadata": {
        "id": "iEBEcS6zk3f_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BALTz_uKj0GI"
      },
      "outputs": [],
      "source": [
        "!pip install -qU datasets torchinfo openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opH8A_N6llrm",
        "outputId": "585ab899-5a1b-42a1-d945-050b94af044f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "njTe_Stdk7UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistilBert Finetuning by Huggingface Trainer\n",
        "Task:\n",
        "nyu-mll/glue의 mnli 데이터셋에 대한 distill bert의 분류 성능을 측정해야 합니다.\n",
        "더 해볼 과제:\n",
        "언어 모델 앙상블과 chain of thought prompt engineering을 통해 텍스트를 분류해볼 것입니다.\n",
        "\n",
        "openai api 또한 간단히 사용할 예정입니다.\n",
        "\n",
        "Distill bert로 분류한 것과 간단히 성능을 비교해보겠습니다."
      ],
      "metadata": {
        "id": "eD5N65pKnOsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# 모델 config입니다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "ds_name = \"nyu-mll/glue\"\n",
        "ds_config = \"mnli\"\n",
        "\n",
        "n_labels = 3\n",
        "\n",
        "test_size1 = 0.1\n",
        "test_size2 = 0.2222\n",
        "random_state = 42\n",
        "batch_size = 64\n",
        "max_len = 400\n",
        "\n",
        "results_dir = './results/week4_basic'\n",
        "lr = 2e-5\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "BFtQjJuVnP8X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "import pandas as pd #pandas : 데이터조작 및 분석용 sw lib\n",
        "\n",
        "# Parquet 형태의 데이터셋입니다.\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=n_labels)\n",
        "model = model.to(device)\n",
        "raw_dataset = load_dataset(ds_name, ds_config)\n",
        "label2idx = {'entailment':0,'neutral':1,'contradiction':2}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jieUpWXInWHp",
        "outputId": "a90dbc69-964d-43a1-94e0-8cef22cabf00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchinfo import summary\n",
        "# 모델 정보 출력\n",
        "vocab_size = len(tokenizer)\n",
        "# vocab 안에서의 인덱스까지의 데이터\n",
        "dummy_input_ids = torch.randint(0, vocab_size, (batch_size, max_len))\n",
        "dummy_attention_mask = torch.ones(batch_size, max_len, dtype=torch.int64)\n",
        "\n",
        "# 모델 요약 출력\n",
        "print(\"Model Summary\")\n",
        "print(\"Vocab_size \", vocab_size)\n",
        "print(\"Input Shape \", dummy_input_ids.shape)\n",
        "print(\"Attention_Mask Shape \", dummy_attention_mask.shape)\n",
        "print(summary(model, input_data={\"input_ids\": dummy_input_ids.to(device), \"attention_mask\": dummy_attention_mask.to(device)}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B95YVVRgnbfl",
        "outputId": "cc5fc095-3ec4-49e3-f36c-de8f2ab6dd72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary\n",
            "Vocab_size  30522\n",
            "Input Shape  torch.Size([64, 400])\n",
            "Attention_Mask Shape  torch.Size([64, 400])\n",
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "DistilBertForSequenceClassification                     [64, 3]                   --\n",
            "├─DistilBertModel: 1-1                                  [64, 400, 768]            --\n",
            "│    └─Embeddings: 2-1                                  [64, 400, 768]            --\n",
            "│    │    └─Embedding: 3-1                              [64, 400, 768]            23,440,896\n",
            "│    │    └─Embedding: 3-2                              [1, 400, 768]             393,216\n",
            "│    │    └─LayerNorm: 3-3                              [64, 400, 768]            1,536\n",
            "│    │    └─Dropout: 3-4                                [64, 400, 768]            --\n",
            "│    └─Transformer: 2-2                                 [64, 400, 768]            --\n",
            "│    │    └─ModuleList: 3-5                             --                        42,527,232\n",
            "├─Linear: 1-2                                           [64, 768]                 590,592\n",
            "├─Dropout: 1-3                                          [64, 768]                 --\n",
            "├─Linear: 1-4                                           [64, 3]                   2,307\n",
            "=========================================================================================================\n",
            "Total params: 66,955,779\n",
            "Trainable params: 66,955,779\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 4.26\n",
            "=========================================================================================================\n",
            "Input size (MB): 0.41\n",
            "Forward/backward pass size (MB): 10698.33\n",
            "Params size (MB): 267.82\n",
            "Estimated Total Size (MB): 10966.56\n",
            "=========================================================================================================\n"
          ]
        }
      ]
    }
  ]
}